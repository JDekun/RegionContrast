{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zk/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use_env is set by default in torchrun.\n",
      "If your script expects `--local_rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  warnings.warn(\n",
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "rank,world_size 1 4\n",
      "set random seed to 123\n",
      "rank,world_size 3 4\n",
      "set random seed to 123\n",
      "rank,world_size 2 4\n",
      "set random seed to 123\n",
      "rank,world_size 0 4\n",
      "2023-04-09 10:30:08,073-rk0-train_contrast.py#63:{'dataset': {'type': 'cityscapes', 'train': {'data_root': '../../../../input/cityscapes/Cityscape', 'data_list': './cityscapes/train.txt', 'flip': True, 'GaussianBlur': False, 'rand_resize': [0.5, 2.0], 'crop': {'type': 'rand', 'size': [769, 769]}}, 'val': {'data_root': '../../../../input/cityscapes/Cityscape', 'data_list': './cityscapes/val.txt', 'crop': {'type': 'center', 'size': [769, 769]}}, 'batch_size': 2, 'batch_size_val': 12, 'workers': 1, 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'ignore_label': 255}, 'trainer': {'epochs': 100, 'start_epochs': 0, 'eval_on': True, 'optimizer': {'type': 'SGD', 'kwargs': {'lr': 0.01, 'momentum': 0.9, 'weight_decay': 0.0005}}, 'lr_scheduler': {'mode': 'poly', 'kwargs': {'power': 0.9}}}, 'saver': {'snapshot_dir': 'checkpoints', 'pretrain': ''}, 'criterion': {'type': 'ohem', 'contrast_weight': 0.1, 'kwargs': {'thresh': 0.7, 'min_kept': 100000}}, 'net': {'num_classes': 19, 'sync_bn': True, 'aux_loss': {'aux_plane': 1024, 'loss_weight': 0.4}, 'encoder': {'type': 'pyseg.models.resnet.resnet50', 'kwargs': {'multi_grid': True, 'zero_init_residual': True, 'replace_stride_with_dilation': [False, True, True]}}, 'decoder': {'type': 'pyseg.models.decoder_contrast.dec_deeplabv3_contrast', 'kwargs': {'inner_planes': 256, 'dilations': [12, 24, 36]}}}}\n",
      "set random seed to 123\n",
      "missing_keys:  []\n",
      "unexpected_keys:  ['fc.weight', 'fc.bias']\n",
      "missing_keys:  []\n",
      "unexpected_keys:  ['fc.weight', 'fc.bias']\n",
      "missing_keys:  []\n",
      "unexpected_keys:  ['fc.weight', 'fc.bias']\n",
      "missing_keys:  []\n",
      "unexpected_keys:  ['fc.weight', 'fc.bias']\n",
      "2023-04-09 10:30:12,775-rk0-train_contrast.py#105:DistributedDataParallel(\n",
      "  (module): ModelBuilder(\n",
      "    (encoder): ResNet(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=True)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
      "          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): dec_deeplabv3_contrast(\n",
      "      (criterion): CrossEntropyLoss()\n",
      "      (aspp): ASPP(\n",
      "        (conv1): Sequential(\n",
      "          (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Sequential(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): Sequential(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
      "          (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv4): Sequential(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
      "          (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv5): Sequential(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
      "          (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (head): Sequential(\n",
      "        (0): Conv2d(1280, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Dropout2d(p=0.1, inplace=False)\n",
      "      )\n",
      "      (final): Conv2d(256, 19, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (auxor): Aux_Module(\n",
      "      (aux): Sequential(\n",
      "        (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Dropout2d(p=0.1, inplace=False)\n",
      "        (4): Conv2d(256, 19, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "2023-04-09 10:30:12,781-rk0-base.py#25:# samples: 2975\n",
      "2023-04-09 10:30:12,782-rk0-base.py#25:# samples: 500\n",
      "2023-04-09 10:30:12,782-rk0-builder.py#15:Get loader Done...\n",
      "2023-04-09 10:30:12,783-rk0-lr_helper.py#59:The kwargs for lr scheduler: 0.9\n",
      "2023-04-09 10:30:12,784-rk0-train_contrast.py#172:=========epoch[0]=========,Train\n",
      "2023-04-09 10:30:12,803-rk0-base.py#25:# samples: 2975\n",
      "2023-04-09 10:30:12,804-rk0-base.py#25:# samples: 2975\n",
      "2023-04-09 10:30:12,805-rk0-base.py#25:# samples: 500\n",
      "2023-04-09 10:30:12,805-rk0-builder.py#15:Get loader Done...\n",
      "2023-04-09 10:30:12,805-rk0-base.py#25:# samples: 2975\n",
      "2023-04-09 10:30:12,806-rk0-lr_helper.py#59:The kwargs for lr scheduler: 0.9\n",
      "2023-04-09 10:30:12,807-rk0-base.py#25:# samples: 500\n",
      "2023-04-09 10:30:12,807-rk0-builder.py#15:Get loader Done...\n",
      "2023-04-09 10:30:12,807-rk0-base.py#25:# samples: 500\n",
      "2023-04-09 10:30:12,807-rk0-builder.py#15:Get loader Done...\n",
      "2023-04-09 10:30:12,808-rk0-lr_helper.py#59:The kwargs for lr scheduler: 0.9\n",
      "2023-04-09 10:30:12,808-rk0-lr_helper.py#59:The kwargs for lr scheduler: 0.9\n",
      "/home/zk/anaconda3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "  warnings.warn(\n",
      "/home/zk/anaconda3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "  warnings.warn(\n",
      "/home/zk/anaconda3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "  warnings.warn(\n",
      "/home/zk/anaconda3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "  warnings.warn(\n",
      "/home/zk/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:3734: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/zk/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:3734: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/zk/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:3734: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/zk/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:3734: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "/home/zk/anaconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:13: UserWarning: reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(\"reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\")\n",
      "/home/zk/anaconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:13: UserWarning: reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(\"reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\")\n",
      "/home/zk/anaconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:13: UserWarning: reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(\"reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\")\n",
      "/home/zk/anaconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:13: UserWarning: reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(\"reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\")\n",
      "2023-04-09 10:30:27,061-rk0-train_contrast.py#230:iter = 0 of 37200 completed, LR = [0.01, 0.1, 0.1] loss = 20.746347427368164\n",
      "2023-04-09 10:31:23,686-rk0-train_contrast.py#230:iter = 50 of 37200 completed, LR = [0.009987902412450263, 0.09987902412450264, 0.09987902412450264] loss = 8.867739789626178\n",
      "2023-04-09 10:32:20,646-rk0-train_contrast.py#230:iter = 100 of 37200 completed, LR = [0.009975803196582153, 0.09975803196582153, 0.09975803196582153] loss = 9.093323537618806\n",
      "2023-04-09 10:33:18,350-rk0-train_contrast.py#230:iter = 150 of 37200 completed, LR = [0.009963702349981554, 0.09963702349981554, 0.09963702349981554] loss = 9.639119104044326\n",
      "2023-04-09 10:34:16,097-rk0-train_contrast.py#230:iter = 200 of 37200 completed, LR = [0.00995159987022751, 0.09951599870227511, 0.09951599870227511] loss = 10.063395187036315\n",
      "2023-04-09 10:35:13,927-rk0-train_contrast.py#230:iter = 250 of 37200 completed, LR = [0.009939495754892199, 0.09939495754892198, 0.09939495754892198] loss = 10.373662359686012\n",
      "2023-04-09 10:36:11,887-rk0-train_contrast.py#230:iter = 300 of 37200 completed, LR = [0.009927390001540892, 0.09927390001540892, 0.09927390001540892] loss = 10.640344154003055\n",
      "2023-04-09 10:37:09,708-rk0-train_contrast.py#230:iter = 350 of 37200 completed, LR = [0.009915282607731935, 0.09915282607731934, 0.09915282607731934] loss = 10.842436429102536\n",
      "2023-04-09 10:37:33,890-rk0-train_contrast.py#253:=========epoch[0]=========,Val\n",
      "2023-04-09 10:37:47,005-rk0-train_contrast.py#284:iter = 0 of 11 completed\n",
      "2023-04-09 10:37:57,331-rk0-train_contrast.py#284:iter = 5 of 11 completed\n",
      "2023-04-09 10:38:10,497-rk0-train_contrast.py#284:iter = 10 of 11 completed\n",
      "2023-04-09 10:38:10,669-rk0-train_contrast.py#293:accuracy = 0.4861501515929547 mIoU = 0.3854337040064523\n",
      "2023-04-09 10:38:11,548-rk0-train_contrast.py#149:the best val result is: 0.3854337040064523\n",
      "2023-04-09 10:38:11,550-rk0-train_contrast.py#172:=========epoch[1]=========,Train\n",
      "2023-04-09 10:38:46,776-rk0-train_contrast.py#230:iter = 400 of 37200 completed, LR = [0.009903173571016716, 0.09903173571016716, 0.09903173571016716] loss = 11.89823735993484\n",
      "2023-04-09 10:39:45,441-rk0-train_contrast.py#230:iter = 450 of 37200 completed, LR = [0.009891062888939638, 0.09891062888939639, 0.09891062888939639] loss = 11.982763386979888\n",
      "2023-04-09 10:40:44,058-rk0-train_contrast.py#230:iter = 500 of 37200 completed, LR = [0.009878950559038086, 0.09878950559038085, 0.09878950559038085] loss = 12.051134700923003\n",
      "2023-04-09 10:41:42,494-rk0-train_contrast.py#230:iter = 550 of 37200 completed, LR = [0.009866836578842395, 0.09866836578842396, 0.09866836578842396] loss = 12.146976875859266\n",
      "2023-04-09 10:42:40,643-rk0-train_contrast.py#230:iter = 600 of 37200 completed, LR = [0.009854720945875832, 0.09854720945875832, 0.09854720945875832] loss = 12.188135051310843\n",
      "2023-04-09 10:43:38,691-rk0-train_contrast.py#230:iter = 650 of 37200 completed, LR = [0.009842603657654549, 0.0984260365765455, 0.0984260365765455] loss = 12.233112215568514\n",
      "2023-04-09 10:44:36,816-rk0-train_contrast.py#230:iter = 700 of 37200 completed, LR = [0.00983048471168757, 0.0983048471168757, 0.0983048471168757] loss = 12.252497907829865\n",
      "2023-04-09 10:45:26,775-rk0-train_contrast.py#253:=========epoch[1]=========,Val\n",
      "2023-04-09 10:45:33,250-rk0-train_contrast.py#284:iter = 0 of 11 completed\n",
      "2023-04-09 10:45:44,490-rk0-train_contrast.py#284:iter = 5 of 11 completed\n",
      "2023-04-09 10:45:53,652-rk0-train_contrast.py#284:iter = 10 of 11 completed\n",
      "2023-04-09 10:45:53,822-rk0-train_contrast.py#293:accuracy = 0.5980096740150984 mIoU = 0.47490747669815647\n",
      "2023-04-09 10:45:56,327-rk0-train_contrast.py#149:the best val result is: 0.47490747669815647\n",
      "2023-04-09 10:45:56,328-rk0-train_contrast.py#172:=========epoch[2]=========,Train\n",
      "2023-04-09 10:46:05,787-rk0-train_contrast.py#230:iter = 750 of 37200 completed, LR = [0.009818364105476748, 0.0981836410547675, 0.0981836410547675] loss = 13.106161117553711\n",
      "2023-04-09 10:47:03,982-rk0-train_contrast.py#230:iter = 800 of 37200 completed, LR = [0.009806241836516743, 0.09806241836516744, 0.09806241836516744] loss = 12.554542943050986\n",
      "2023-04-09 10:48:03,065-rk0-train_contrast.py#230:iter = 850 of 37200 completed, LR = [0.009794117902294982, 0.09794117902294983, 0.09794117902294983] loss = 12.342750834527417\n",
      "2023-04-09 10:49:01,637-rk0-train_contrast.py#230:iter = 900 of 37200 completed, LR = [0.009781992300291639, 0.09781992300291639, 0.09781992300291639] loss = 12.311420999514828\n",
      "2023-04-09 10:50:00,215-rk0-train_contrast.py#230:iter = 950 of 37200 completed, LR = [0.009769865027979593, 0.09769865027979595, 0.09769865027979595] loss = 12.338652191530679\n",
      "2023-04-09 10:50:58,799-rk0-train_contrast.py#230:iter = 1000 of 37200 completed, LR = [0.009757736082824412, 0.09757736082824413, 0.09757736082824413] loss = 12.329754654999373\n",
      "2023-04-09 10:51:57,334-rk0-train_contrast.py#230:iter = 1050 of 37200 completed, LR = [0.009745605462284302, 0.09745605462284301, 0.09745605462284301] loss = 12.358383958425119\n",
      "2023-04-09 10:52:55,535-rk0-train_contrast.py#230:iter = 1100 of 37200 completed, LR = [0.00973347316381009, 0.09733473163810091, 0.09733473163810091] loss = 12.372069024906105\n",
      "2023-04-09 10:53:12,991-rk0-train_contrast.py#253:=========epoch[2]=========,Val\n",
      "2023-04-09 10:53:19,457-rk0-train_contrast.py#284:iter = 0 of 11 completed\n",
      "2023-04-09 10:53:30,206-rk0-train_contrast.py#284:iter = 5 of 11 completed\n",
      "2023-04-09 10:53:39,414-rk0-train_contrast.py#284:iter = 10 of 11 completed\n",
      "2023-04-09 10:53:39,611-rk0-train_contrast.py#293:accuracy = 0.6433644678920077 mIoU = 0.5364910618390786\n",
      "2023-04-09 10:53:41,922-rk0-train_contrast.py#149:the best val result is: 0.5364910618390786\n",
      "2023-04-09 10:53:41,924-rk0-train_contrast.py#172:=========epoch[3]=========,Train\n",
      "2023-04-09 10:54:23,790-rk0-train_contrast.py#230:iter = 1150 of 37200 completed, LR = [0.00972133918484519, 0.0972133918484519, 0.0972133918484519] loss = 12.72189143044608\n",
      "2023-04-09 10:55:21,916-rk0-train_contrast.py#230:iter = 1200 of 37200 completed, LR = [0.009709203522825567, 0.09709203522825567, 0.09709203522825567] loss = 12.591254918715533\n",
      "2023-04-09 10:56:20,047-rk0-train_contrast.py#230:iter = 1250 of 37200 completed, LR = [0.009697066175179707, 0.09697066175179707, 0.09697066175179707] loss = 12.557070393032499\n",
      "2023-04-09 10:57:19,304-rk0-train_contrast.py#230:iter = 1300 of 37200 completed, LR = [0.009684927139328583, 0.09684927139328582, 0.09684927139328582] loss = 12.5174472654188\n",
      "2023-04-09 10:58:18,083-rk0-train_contrast.py#230:iter = 1350 of 37200 completed, LR = [0.009672786412685626, 0.09672786412685627, 0.09672786412685627] loss = 12.611594906259091\n",
      "2023-04-09 10:59:16,282-rk0-train_contrast.py#230:iter = 1400 of 37200 completed, LR = [0.009660643992656696, 0.09660643992656696, 0.09660643992656696] loss = 12.616651126794649\n",
      "2023-04-09 11:00:14,388-rk0-train_contrast.py#230:iter = 1450 of 37200 completed, LR = [0.009648499876640034, 0.09648499876640035, 0.09648499876640035] loss = 12.593800217358034\n",
      "2023-04-09 11:00:57,491-rk0-train_contrast.py#253:=========epoch[3]=========,Val\n",
      "2023-04-09 11:01:04,073-rk0-train_contrast.py#284:iter = 0 of 11 completed\n",
      "2023-04-09 11:01:14,810-rk0-train_contrast.py#284:iter = 5 of 11 completed\n",
      "2023-04-09 11:01:23,975-rk0-train_contrast.py#284:iter = 10 of 11 completed\n",
      "2023-04-09 11:01:24,142-rk0-train_contrast.py#293:accuracy = 0.6006732289575605 mIoU = 0.5054494159381536\n",
      "2023-04-09 11:01:24,143-rk0-train_contrast.py#149:the best val result is: 0.5364910618390786\n",
      "2023-04-09 11:01:24,144-rk0-train_contrast.py#172:=========epoch[4]=========,Train\n",
      "2023-04-09 11:01:41,033-rk0-train_contrast.py#230:iter = 1500 of 37200 completed, LR = [0.009636354062026247, 0.09636354062026248, 0.09636354062026248] loss = 12.798051467308632\n",
      "2023-04-09 11:02:39,503-rk0-train_contrast.py#230:iter = 1550 of 37200 completed, LR = [0.009624206546198262, 0.09624206546198262, 0.09624206546198262] loss = 12.454720951261974\n",
      "2023-04-09 11:03:37,709-rk0-train_contrast.py#230:iter = 1600 of 37200 completed, LR = [0.009612057326531299, 0.09612057326531298, 0.09612057326531298] loss = 12.369635750762129\n",
      "2023-04-09 11:04:36,085-rk0-train_contrast.py#230:iter = 1650 of 37200 completed, LR = [0.009599906400392835, 0.09599906400392837, 0.09599906400392837] loss = 12.502551792589433\n",
      "2023-04-09 11:05:34,206-rk0-train_contrast.py#230:iter = 1700 of 37200 completed, LR = [0.009587753765142577, 0.09587753765142576, 0.09587753765142576] loss = 12.421922558350182\n",
      "2023-04-09 11:06:32,345-rk0-train_contrast.py#230:iter = 1750 of 37200 completed, LR = [0.009575599418132411, 0.09575599418132412, 0.09575599418132412] loss = 12.408835142737558\n",
      "2023-04-09 11:07:31,904-rk0-train_contrast.py#230:iter = 1800 of 37200 completed, LR = [0.009563443356706388, 0.09563443356706389, 0.09563443356706389] loss = 12.46543054306469\n",
      "2023-04-09 11:08:30,507-rk0-train_contrast.py#230:iter = 1850 of 37200 completed, LR = [0.009551285578200676, 0.09551285578200677, 0.09551285578200677] loss = 12.47964369035621\n",
      "2023-04-09 11:08:40,856-rk0-train_contrast.py#253:=========epoch[4]=========,Val\n",
      "2023-04-09 11:08:46,995-rk0-train_contrast.py#284:iter = 0 of 11 completed\n",
      "2023-04-09 11:08:57,668-rk0-train_contrast.py#284:iter = 5 of 11 completed\n",
      "2023-04-09 11:09:06,780-rk0-train_contrast.py#284:iter = 10 of 11 completed\n",
      "2023-04-09 11:09:06,947-rk0-train_contrast.py#293:accuracy = 0.5831975362053101 mIoU = 0.480500362843688\n",
      "2023-04-09 11:09:06,947-rk0-train_contrast.py#149:the best val result is: 0.5364910618390786\n",
      "2023-04-09 11:09:06,948-rk0-train_contrast.py#172:=========epoch[5]=========,Train\n",
      "2023-04-09 11:09:56,366-rk0-train_contrast.py#230:iter = 1900 of 37200 completed, LR = [0.009539126079943535, 0.09539126079943536, 0.09539126079943536] loss = 12.202427817554009\n",
      "2023-04-09 11:10:54,391-rk0-train_contrast.py#230:iter = 1950 of 37200 completed, LR = [0.009526964859255272, 0.09526964859255271, 0.09526964859255271] loss = 12.433243248488877\n",
      "2023-04-09 11:11:52,529-rk0-train_contrast.py#230:iter = 2000 of 37200 completed, LR = [0.009514801913448211, 0.09514801913448212, 0.09514801913448212] loss = 12.434073285853609\n",
      "2023-04-09 11:12:50,490-rk0-train_contrast.py#230:iter = 2050 of 37200 completed, LR = [0.009502637239826665, 0.09502637239826665, 0.09502637239826665] loss = 12.42947072633274\n",
      "2023-04-09 11:13:48,454-rk0-train_contrast.py#230:iter = 2100 of 37200 completed, LR = [0.009490470835686887, 0.09490470835686887, 0.09490470835686887] loss = 12.46595472122129\n",
      "2023-04-09 11:14:46,558-rk0-train_contrast.py#230:iter = 2150 of 37200 completed, LR = [0.009478302698317042, 0.09478302698317043, 0.09478302698317043] loss = 12.476126205470553\n",
      "2023-04-09 11:15:44,656-rk0-train_contrast.py#230:iter = 2200 of 37200 completed, LR = [0.009466132824997179, 0.09466132824997178, 0.09466132824997178] loss = 12.50085287569555\n",
      "2023-04-09 11:16:20,534-rk0-train_contrast.py#253:=========epoch[5]=========,Val\n",
      "2023-04-09 11:16:26,514-rk0-train_contrast.py#284:iter = 0 of 11 completed\n",
      "2023-04-09 11:16:37,237-rk0-train_contrast.py#284:iter = 5 of 11 completed\n",
      "2023-04-09 11:16:46,345-rk0-train_contrast.py#284:iter = 10 of 11 completed\n",
      "2023-04-09 11:16:46,519-rk0-train_contrast.py#293:accuracy = 0.6653657595801544 mIoU = 0.5598387110917591\n",
      "2023-04-09 11:16:49,086-rk0-train_contrast.py#149:the best val result is: 0.5598387110917591\n",
      "2023-04-09 11:16:49,087-rk0-train_contrast.py#172:=========epoch[6]=========,Train\n",
      "2023-04-09 11:17:12,006-rk0-train_contrast.py#230:iter = 2250 of 37200 completed, LR = [0.00945396121299917, 0.0945396121299917, 0.0945396121299917] loss = 12.256340478595934\n",
      "2023-04-09 11:18:09,989-rk0-train_contrast.py#230:iter = 2300 of 37200 completed, LR = [0.00944178785958671, 0.09441787859586709, 0.09441787859586709] loss = 12.515048731928287\n",
      "2023-04-09 11:19:08,547-rk0-train_contrast.py#230:iter = 2350 of 37200 completed, LR = [0.009429612762015243, 0.09429612762015244, 0.09429612762015244] loss = 12.510766365948845\n",
      "2023-04-09 11:20:08,758-rk0-train_contrast.py#230:iter = 2400 of 37200 completed, LR = [0.009417435917531958, 0.09417435917531958, 0.09417435917531958] loss = 12.4924596131906\n",
      "2023-04-09 11:21:06,776-rk0-train_contrast.py#230:iter = 2450 of 37200 completed, LR = [0.009405257323375726, 0.09405257323375726, 0.09405257323375726] loss = 12.505053472301187\n",
      "2023-04-09 11:22:04,804-rk0-train_contrast.py#230:iter = 2500 of 37200 completed, LR = [0.009393076976777081, 0.09393076976777082, 0.09393076976777082] loss = 12.512055350945342\n",
      "2023-04-09 11:23:02,739-rk0-train_contrast.py#230:iter = 2550 of 37200 completed, LR = [0.009380894874958176, 0.09380894874958176, 0.09380894874958176] loss = 12.532355209876751\n",
      "2023-04-09 11:24:00,964-rk0-train_contrast.py#230:iter = 2600 of 37200 completed, LR = [0.009368711015132742, 0.09368711015132743, 0.09368711015132743] loss = 12.564871015264412\n",
      "2023-04-09 11:24:04,556-rk0-train_contrast.py#253:=========epoch[6]=========,Val\n",
      "2023-04-09 11:24:10,880-rk0-train_contrast.py#284:iter = 0 of 11 completed\n",
      "2023-04-09 11:24:21,528-rk0-train_contrast.py#284:iter = 5 of 11 completed\n",
      "2023-04-09 11:24:30,714-rk0-train_contrast.py#284:iter = 10 of 11 completed\n",
      "2023-04-09 11:24:30,914-rk0-train_contrast.py#293:accuracy = 0.6882785428152264 mIoU = 0.5570329402692142\n",
      "2023-04-09 11:24:30,915-rk0-train_contrast.py#149:the best val result is: 0.5598387110917591\n",
      "2023-04-09 11:24:30,917-rk0-train_contrast.py#172:=========epoch[7]=========,Train\n",
      "2023-04-09 11:25:27,099-rk0-train_contrast.py#230:iter = 2650 of 37200 completed, LR = [0.009356525394506057, 0.09356525394506057, 0.09356525394506057] loss = 12.361700321765657\n",
      "2023-04-09 11:26:25,410-rk0-train_contrast.py#230:iter = 2700 of 37200 completed, LR = [0.009344338010274903, 0.09344338010274904, 0.09344338010274904] loss = 12.517897212628236\n",
      "2023-04-09 11:27:23,629-rk0-train_contrast.py#230:iter = 2750 of 37200 completed, LR = [0.009332148859627534, 0.09332148859627534, 0.09332148859627534] loss = 12.423932665870304\n",
      "2023-04-09 11:28:21,935-rk0-train_contrast.py#230:iter = 2800 of 37200 completed, LR = [0.009319957939743627, 0.09319957939743627, 0.09319957939743627] loss = 12.436821066183487\n",
      "2023-04-09 11:29:20,081-rk0-train_contrast.py#230:iter = 2850 of 37200 completed, LR = [0.009307765247794255, 0.09307765247794254, 0.09307765247794254] loss = 12.46525132414783\n",
      "2023-04-09 11:30:18,381-rk0-train_contrast.py#230:iter = 2900 of 37200 completed, LR = [0.00929557078094184, 0.0929557078094184, 0.0929557078094184] loss = 12.520386031179717\n",
      "2023-04-09 11:31:16,430-rk0-train_contrast.py#230:iter = 2950 of 37200 completed, LR = [0.009283374536340119, 0.0928337453634012, 0.0928337453634012] loss = 12.471732851407713\n",
      "2023-04-09 11:31:46,192-rk0-train_contrast.py#253:=========epoch[7]=========,Val\n",
      "2023-04-09 11:31:52,515-rk0-train_contrast.py#284:iter = 0 of 11 completed\n",
      "2023-04-09 11:32:03,254-rk0-train_contrast.py#284:iter = 5 of 11 completed\n",
      "2023-04-09 11:32:12,370-rk0-train_contrast.py#284:iter = 10 of 11 completed\n",
      "2023-04-09 11:32:12,585-rk0-train_contrast.py#293:accuracy = 0.6955810961284706 mIoU = 0.5838865770746399\n",
      "2023-04-09 11:32:15,080-rk0-train_contrast.py#149:the best val result is: 0.5838865770746399\n",
      "2023-04-09 11:32:15,083-rk0-train_contrast.py#172:=========epoch[8]=========,Train\n",
      "2023-04-09 11:32:47,018-rk0-train_contrast.py#230:iter = 3000 of 37200 completed, LR = [0.009271176511134101, 0.09271176511134102, 0.09271176511134102] loss = 12.38254768371582\n",
      "2023-04-09 11:33:46,903-rk0-train_contrast.py#230:iter = 3050 of 37200 completed, LR = [0.009258976702460031, 0.09258976702460031, 0.09258976702460031] loss = 12.519421590169271\n",
      "2023-04-09 11:34:45,186-rk0-train_contrast.py#230:iter = 3100 of 37200 completed, LR = [0.009246775107445347, 0.09246775107445347, 0.09246775107445347] loss = 12.535509376525878\n",
      "2023-04-09 11:35:43,214-rk0-train_contrast.py#230:iter = 3150 of 37200 completed, LR = [0.00923457172320864, 0.0923457172320864, 0.0923457172320864] loss = 12.511255193437849\n",
      "2023-04-09 11:36:41,440-rk0-train_contrast.py#230:iter = 3200 of 37200 completed, LR = [0.009222366546859614, 0.09222366546859614, 0.09222366546859614] loss = 12.465472272237141\n",
      "2023-04-09 11:37:39,463-rk0-train_contrast.py#230:iter = 3250 of 37200 completed, LR = [0.009210159575499054, 0.09210159575499054, 0.09210159575499054] loss = 12.467985735806552\n",
      "2023-04-09 11:38:37,695-rk0-train_contrast.py#230:iter = 3300 of 37200 completed, LR = [0.009197950806218767, 0.09197950806218767, 0.09197950806218767] loss = 12.50651268005371\n",
      "2023-04-09 11:39:32,424-rk0-train_contrast.py#253:=========epoch[8]=========,Val\n",
      "2023-04-09 11:39:38,626-rk0-train_contrast.py#284:iter = 0 of 11 completed\n",
      "2023-04-09 11:39:49,635-rk0-train_contrast.py#284:iter = 5 of 11 completed\n",
      "2023-04-09 11:39:58,782-rk0-train_contrast.py#284:iter = 10 of 11 completed\n",
      "2023-04-09 11:39:58,973-rk0-train_contrast.py#293:accuracy = 0.7314643502638581 mIoU = 0.5959750962319591\n",
      "2023-04-09 11:40:01,500-rk0-train_contrast.py#149:the best val result is: 0.5959750962319591\n",
      "2023-04-09 11:40:01,502-rk0-train_contrast.py#172:=========epoch[9]=========,Train\n",
      "2023-04-09 11:40:06,524-rk0-train_contrast.py#230:iter = 3350 of 37200 completed, LR = [0.009185740236101558, 0.09185740236101558, 0.09185740236101558] loss = 12.251959800720215\n",
      "2023-04-09 11:41:04,811-rk0-train_contrast.py#230:iter = 3400 of 37200 completed, LR = [0.009173527862221184, 0.09173527862221185, 0.09173527862221185] loss = 12.922758192386267\n",
      "2023-04-09 11:42:02,984-rk0-train_contrast.py#230:iter = 3450 of 37200 completed, LR = [0.009161313681642308, 0.09161313681642308, 0.09161313681642308] loss = 12.681118381833567\n",
      "2023-04-09 11:43:01,602-rk0-train_contrast.py#230:iter = 3500 of 37200 completed, LR = [0.009149097691420456, 0.09149097691420456, 0.09149097691420456] loss = 12.678317637225382\n",
      "2023-04-09 11:43:59,728-rk0-train_contrast.py#230:iter = 3550 of 37200 completed, LR = [0.009136879888601986, 0.09136879888601987, 0.09136879888601987] loss = 12.634874630444155\n",
      "2023-04-09 11:44:57,880-rk0-train_contrast.py#230:iter = 3600 of 37200 completed, LR = [0.009124660270224037, 0.09124660270224039, 0.09124660270224039] loss = 12.590328759355508\n",
      "2023-04-09 11:45:56,993-rk0-train_contrast.py#230:iter = 3650 of 37200 completed, LR = [0.009112438833314489, 0.0911243883331449, 0.0911243883331449] loss = 12.619795317697053\n",
      "2023-04-09 11:46:55,265-rk0-train_contrast.py#230:iter = 3700 of 37200 completed, LR = [0.009100215574891915, 0.09100215574891916, 0.09100215574891916] loss = 12.628645745620512\n",
      "2023-04-09 11:47:17,230-rk0-train_contrast.py#253:=========epoch[9]=========,Val\n",
      "2023-04-09 11:47:23,471-rk0-train_contrast.py#284:iter = 0 of 11 completed\n",
      "2023-04-09 11:47:34,116-rk0-train_contrast.py#284:iter = 5 of 11 completed\n",
      "2023-04-09 11:47:43,288-rk0-train_contrast.py#284:iter = 10 of 11 completed\n",
      "2023-04-09 11:47:43,489-rk0-train_contrast.py#293:accuracy = 0.5888949457798653 mIoU = 0.4771935122878438\n",
      "2023-04-09 11:47:43,490-rk0-train_contrast.py#149:the best val result is: 0.5959750962319591\n",
      "2023-04-09 11:47:43,493-rk0-train_contrast.py#172:=========epoch[10]=========,Train\n",
      "2023-04-09 11:48:22,953-rk0-train_contrast.py#230:iter = 3750 of 37200 completed, LR = [0.009087990491965549, 0.09087990491965549, 0.09087990491965549] loss = 12.455256123696604\n",
      "2023-04-09 11:49:22,006-rk0-train_contrast.py#230:iter = 3800 of 37200 completed, LR = [0.009075763581535229, 0.09075763581535229, 0.09075763581535229] loss = 12.528498461217056\n",
      "2023-04-09 11:50:20,219-rk0-train_contrast.py#230:iter = 3850 of 37200 completed, LR = [0.009063534840591369, 0.0906353484059137, 0.0906353484059137] loss = 12.678094012136677\n",
      "2023-04-09 11:51:18,517-rk0-train_contrast.py#230:iter = 3900 of 37200 completed, LR = [0.009051304266114899, 0.090513042661149, 0.090513042661149] loss = 12.668940886608144\n",
      "2023-04-09 11:52:16,357-rk0-train_contrast.py#230:iter = 3950 of 37200 completed, LR = [0.009039071855077236, 0.09039071855077235, 0.09039071855077235] loss = 12.625815560807398\n",
      "2023-04-09 11:53:14,527-rk0-train_contrast.py#230:iter = 4000 of 37200 completed, LR = [0.009026837604440225, 0.09026837604440224, 0.09026837604440224] loss = 12.663949579530764\n",
      "2023-04-09 11:54:12,610-rk0-train_contrast.py#230:iter = 4050 of 37200 completed, LR = [0.009014601511156106, 0.09014601511156106, 0.09014601511156106] loss = 12.624227422962015\n",
      "2023-04-09 11:55:00,316-rk0-train_contrast.py#253:=========epoch[10]=========,Val\n",
      "2023-04-09 11:55:06,788-rk0-train_contrast.py#284:iter = 0 of 11 completed\n",
      "2023-04-09 11:55:17,576-rk0-train_contrast.py#284:iter = 5 of 11 completed\n",
      "2023-04-09 11:55:26,725-rk0-train_contrast.py#284:iter = 10 of 11 completed\n",
      "2023-04-09 11:55:26,935-rk0-train_contrast.py#293:accuracy = 0.7457711312879735 mIoU = 0.6299590498132512\n",
      "2023-04-09 11:55:29,447-rk0-train_contrast.py#149:the best val result is: 0.6299590498132512\n",
      "2023-04-09 11:55:29,450-rk0-train_contrast.py#172:=========epoch[11]=========,Train\n",
      "2023-04-09 11:55:41,828-rk0-train_contrast.py#230:iter = 4100 of 37200 completed, LR = [0.009002363572167464, 0.09002363572167466, 0.09002363572167466] loss = 12.519556469387478\n",
      "2023-04-09 11:56:39,784-rk0-train_contrast.py#230:iter = 4150 of 37200 completed, LR = [0.008990123784407188, 0.08990123784407188, 0.08990123784407188] loss = 12.543506832446083\n",
      "2023-04-09 11:57:37,780-rk0-train_contrast.py#230:iter = 4200 of 37200 completed, LR = [0.008977882144798412, 0.08977882144798412, 0.08977882144798412] loss = 12.652945868465878\n",
      "2023-04-09 11:58:36,025-rk0-train_contrast.py#230:iter = 4250 of 37200 completed, LR = [0.008965638650254489, 0.0896563865025449, 0.0896563865025449] loss = 12.679624599480778\n",
      "2023-04-09 11:59:34,268-rk0-train_contrast.py#230:iter = 4300 of 37200 completed, LR = [0.008953393297678934, 0.08953393297678934, 0.08953393297678934] loss = 12.69671614432449\n",
      "2023-04-09 12:00:32,498-rk0-train_contrast.py#230:iter = 4350 of 37200 completed, LR = [0.008941146083965372, 0.08941146083965372, 0.08941146083965372] loss = 12.702974938057565\n",
      "2023-04-09 12:01:30,709-rk0-train_contrast.py#230:iter = 4400 of 37200 completed, LR = [0.008928897005997506, 0.08928897005997506, 0.08928897005997506] loss = 12.703116241010648\n",
      "2023-04-09 12:02:29,871-rk0-train_contrast.py#230:iter = 4450 of 37200 completed, LR = [0.008916646060649057, 0.08916646060649058, 0.08916646060649058] loss = 12.70786633664187\n",
      "2023-04-09 12:02:45,099-rk0-train_contrast.py#253:=========epoch[11]=========,Val\n",
      "2023-04-09 12:02:51,948-rk0-train_contrast.py#284:iter = 0 of 11 completed\n",
      "2023-04-09 12:03:02,664-rk0-train_contrast.py#284:iter = 5 of 11 completed\n",
      "2023-04-09 12:03:11,871-rk0-train_contrast.py#284:iter = 10 of 11 completed\n",
      "2023-04-09 12:03:12,070-rk0-train_contrast.py#293:accuracy = 0.6060805944690619 mIoU = 0.49866191470341015\n",
      "2023-04-09 12:03:12,071-rk0-train_contrast.py#149:the best val result is: 0.6299590498132512\n",
      "2023-04-09 12:03:12,072-rk0-train_contrast.py#172:=========epoch[12]=========,Train\n",
      "2023-04-09 12:03:56,890-rk0-train_contrast.py#230:iter = 4500 of 37200 completed, LR = [0.008904393244783728, 0.08904393244783727, 0.08904393244783727] loss = 12.871701472514385\n",
      "2023-04-09 12:04:55,079-rk0-train_contrast.py#230:iter = 4550 of 37200 completed, LR = [0.008892138555255143, 0.08892138555255143, 0.08892138555255143] loss = 12.701043424935177\n",
      "2023-04-09 12:05:55,511-rk0-train_contrast.py#230:iter = 4600 of 37200 completed, LR = [0.00887988198890681, 0.08879881988906811, 0.08879881988906811] loss = 12.734482556363963\n",
      "2023-04-09 12:06:54,978-rk0-train_contrast.py#230:iter = 4650 of 37200 completed, LR = [0.008867623542572074, 0.08867623542572073, 0.08867623542572073] loss = 12.75399713975223\n",
      "2023-04-09 12:07:53,185-rk0-train_contrast.py#230:iter = 4700 of 37200 completed, LR = [0.008855363213074056, 0.08855363213074056, 0.08855363213074056] loss = 12.731124656612863\n",
      "2023-04-09 12:08:51,428-rk0-train_contrast.py#230:iter = 4750 of 37200 completed, LR = [0.00884310099722562, 0.0884310099722562, 0.0884310099722562] loss = 12.682678867300213\n",
      "2023-04-09 12:09:49,404-rk0-train_contrast.py#230:iter = 4800 of 37200 completed, LR = [0.00883083689182931, 0.08830836891829309, 0.08830836891829309] loss = 12.602091061962819\n",
      "2023-04-09 12:10:30,247-rk0-train_contrast.py#253:=========epoch[12]=========,Val\n",
      "2023-04-09 12:10:36,394-rk0-train_contrast.py#284:iter = 0 of 11 completed\n",
      "2023-04-09 12:10:46,985-rk0-train_contrast.py#284:iter = 5 of 11 completed\n",
      "2023-04-09 12:10:56,109-rk0-train_contrast.py#284:iter = 10 of 11 completed\n",
      "2023-04-09 12:10:56,304-rk0-train_contrast.py#293:accuracy = 0.7071352832798086 mIoU = 0.5748111870936097\n",
      "2023-04-09 12:10:56,305-rk0-train_contrast.py#149:the best val result is: 0.6299590498132512\n",
      "2023-04-09 12:10:56,307-rk0-train_contrast.py#172:=========epoch[13]=========,Train\n",
      "2023-04-09 12:11:15,302-rk0-train_contrast.py#230:iter = 4850 of 37200 completed, LR = [0.00881857089367731, 0.08818570893677312, 0.08818570893677312] loss = 12.406195386250813\n",
      "2023-04-09 12:12:13,413-rk0-train_contrast.py#230:iter = 4900 of 37200 completed, LR = [0.008806302999551397, 0.08806302999551396, 0.08806302999551396] loss = 12.586988493112417\n",
      "2023-04-09 12:13:11,816-rk0-train_contrast.py#230:iter = 4950 of 37200 completed, LR = [0.008794033206222874, 0.08794033206222873, 0.08794033206222873] loss = 12.512594397171684\n",
      "2023-04-09 12:14:10,235-rk0-train_contrast.py#230:iter = 5000 of 37200 completed, LR = [0.008781761510452539, 0.08781761510452539, 0.08781761510452539] loss = 12.57290521101518\n",
      "2023-04-09 12:15:08,416-rk0-train_contrast.py#230:iter = 5050 of 37200 completed, LR = [0.008769487908990624, 0.08769487908990625, 0.08769487908990625] loss = 12.613116539356321\n",
      "2023-04-09 12:16:06,448-rk0-train_contrast.py#230:iter = 5100 of 37200 completed, LR = [0.00875721239857675, 0.0875721239857675, 0.0875721239857675] loss = 12.607138601339088\n",
      "2023-04-09 12:17:04,523-rk0-train_contrast.py#230:iter = 5150 of 37200 completed, LR = [0.008744934975939866, 0.08744934975939866, 0.08744934975939866] loss = 12.600969921596466\n",
      "2023-04-09 12:18:02,969-rk0-train_contrast.py#230:iter = 5200 of 37200 completed, LR = [0.00873265563779821, 0.0873265563779821, 0.0873265563779821] loss = 12.612867521259883\n",
      "2023-04-09 12:18:11,163-rk0-train_contrast.py#253:=========epoch[13]=========,Val\n",
      "2023-04-09 12:18:17,396-rk0-train_contrast.py#284:iter = 0 of 11 completed\n",
      "2023-04-09 12:18:27,955-rk0-train_contrast.py#284:iter = 5 of 11 completed\n",
      "2023-04-09 12:18:36,999-rk0-train_contrast.py#284:iter = 10 of 11 completed\n",
      "2023-04-09 12:18:37,226-rk0-train_contrast.py#293:accuracy = 0.6172817745094071 mIoU = 0.48693952872045093\n",
      "2023-04-09 12:18:37,227-rk0-train_contrast.py#149:the best val result is: 0.6299590498132512\n",
      "2023-04-09 12:18:37,229-rk0-train_contrast.py#172:=========epoch[14]=========,Train\n",
      "2023-04-09 12:19:29,584-rk0-train_contrast.py#230:iter = 5250 of 37200 completed, LR = [0.008720374380859248, 0.08720374380859247, 0.08720374380859247] loss = 12.68393128417259\n",
      "2023-04-09 12:20:27,859-rk0-train_contrast.py#230:iter = 5300 of 37200 completed, LR = [0.008708091201819623, 0.08708091201819623, 0.08708091201819623] loss = 12.559357448290752\n",
      "2023-04-09 12:21:26,186-rk0-train_contrast.py#230:iter = 5350 of 37200 completed, LR = [0.008695806097365108, 0.08695806097365108, 0.08695806097365108] loss = 12.621780428853068\n",
      "2023-04-09 12:22:25,579-rk0-train_contrast.py#230:iter = 5400 of 37200 completed, LR = [0.008683519064170546, 0.08683519064170547, 0.08683519064170547] loss = 12.594031319099386\n",
      "2023-04-09 12:23:23,735-rk0-train_contrast.py#230:iter = 5450 of 37200 completed, LR = [0.0086712300988998, 0.08671230098899801, 0.08671230098899801] loss = 12.601768839015882\n",
      "2023-04-09 12:24:22,034-rk0-train_contrast.py#230:iter = 5500 of 37200 completed, LR = [0.008658939198205703, 0.08658939198205703, 0.08658939198205703] loss = 12.602747051382227\n",
      "2023-04-09 12:25:24,479-rk0-train_contrast.py#230:iter = 5550 of 37200 completed, LR = [0.008646646358729995, 0.08646646358729995, 0.08646646358729995] loss = 12.594141987947959\n",
      "2023-04-09 12:25:58,429-rk0-train_contrast.py#253:=========epoch[14]=========,Val\n",
      "2023-04-09 12:26:04,764-rk0-train_contrast.py#284:iter = 0 of 11 completed\n",
      "2023-04-09 12:26:15,420-rk0-train_contrast.py#284:iter = 5 of 11 completed\n",
      "2023-04-09 12:26:24,532-rk0-train_contrast.py#284:iter = 10 of 11 completed\n",
      "2023-04-09 12:26:24,742-rk0-train_contrast.py#293:accuracy = 0.6405963167842441 mIoU = 0.5341853324806168\n",
      "2023-04-09 12:26:24,742-rk0-train_contrast.py#149:the best val result is: 0.6299590498132512\n",
      "2023-04-09 12:26:24,745-rk0-train_contrast.py#172:=========epoch[15]=========,Train\n",
      "2023-04-09 12:26:50,383-rk0-train_contrast.py#230:iter = 5600 of 37200 completed, LR = [0.008634351577103277, 0.08634351577103277, 0.08634351577103277] loss = 12.394338062831334\n",
      "2023-04-09 12:27:48,549-rk0-train_contrast.py#230:iter = 5650 of 37200 completed, LR = [0.008622054849944952, 0.08622054849944952, 0.08622054849944952] loss = 12.487382848497848\n",
      "2023-04-09 12:28:46,881-rk0-train_contrast.py#230:iter = 5700 of 37200 completed, LR = [0.008609756173863172, 0.08609756173863171, 0.08609756173863171] loss = 12.697726131470736\n",
      "2023-04-09 12:29:45,260-rk0-train_contrast.py#230:iter = 5750 of 37200 completed, LR = [0.00859745554545478, 0.08597455545454781, 0.08597455545454781] loss = 12.755476561206127\n",
      "2023-04-09 12:30:43,663-rk0-train_contrast.py#230:iter = 5800 of 37200 completed, LR = [0.008585152961305263, 0.08585152961305265, 0.08585152961305265] loss = 12.727780035717995\n",
      "2023-04-09 12:31:42,074-rk0-train_contrast.py#230:iter = 5850 of 37200 completed, LR = [0.008572848417988681, 0.08572848417988682, 0.08572848417988682] loss = 12.726030451785155\n",
      "2023-04-09 12:32:40,286-rk0-train_contrast.py#230:iter = 5900 of 37200 completed, LR = [0.008560541912067622, 0.08560541912067622, 0.08560541912067622] loss = 12.693679577836367\n",
      "2023-04-09 12:33:38,304-rk0-train_contrast.py#230:iter = 5950 of 37200 completed, LR = [0.008548233440093141, 0.0854823344009314, 0.0854823344009314] loss = 12.701279516811319\n",
      "2023-04-09 12:33:39,611-rk0-train_contrast.py#253:=========epoch[15]=========,Val\n",
      "2023-04-09 12:33:46,216-rk0-train_contrast.py#284:iter = 0 of 11 completed\n",
      "2023-04-09 12:33:57,198-rk0-train_contrast.py#284:iter = 5 of 11 completed\n",
      "2023-04-09 12:34:06,345-rk0-train_contrast.py#284:iter = 10 of 11 completed\n",
      "2023-04-09 12:34:06,609-rk0-train_contrast.py#293:accuracy = 0.7398952963810445 mIoU = 0.6334671588565454\n",
      "2023-04-09 12:34:09,438-rk0-train_contrast.py#149:the best val result is: 0.6334671588565454\n",
      "2023-04-09 12:34:09,440-rk0-train_contrast.py#172:=========epoch[16]=========,Train\n",
      "2023-04-09 12:35:07,790-rk0-train_contrast.py#230:iter = 6000 of 37200 completed, LR = [0.008535922998604705, 0.08535922998604706, 0.08535922998604706] loss = 12.632809697365275\n",
      "2023-04-09 12:36:06,053-rk0-train_contrast.py#230:iter = 6050 of 37200 completed, LR = [0.008523610584130132, 0.08523610584130133, 0.08523610584130133] loss = 12.65214001048695\n",
      "2023-04-09 12:37:04,429-rk0-train_contrast.py#230:iter = 6100 of 37200 completed, LR = [0.008511296193185539, 0.0851129619318554, 0.0851129619318554] loss = 12.691462894414096\n",
      "2023-04-09 12:38:02,752-rk0-train_contrast.py#230:iter = 6150 of 37200 completed, LR = [0.008498979822275274, 0.08498979822275275, 0.08498979822275275] loss = 12.596398669870654\n",
      "2023-04-09 12:39:01,028-rk0-train_contrast.py#230:iter = 6200 of 37200 completed, LR = [0.008486661467891869, 0.08486661467891869, 0.08486661467891869] loss = 12.60225578675787\n",
      "2023-04-09 12:39:59,221-rk0-train_contrast.py#230:iter = 6250 of 37200 completed, LR = [0.00847434112651597, 0.08474341126515969, 0.08474341126515969] loss = 12.568817460816042\n",
      "2023-04-09 12:40:57,430-rk0-train_contrast.py#230:iter = 6300 of 37200 completed, LR = [0.008462018794616282, 0.08462018794616283, 0.08462018794616283] loss = 12.598382837792863\n",
      "2023-04-09 12:41:24,276-rk0-train_contrast.py#253:=========epoch[16]=========,Val\n",
      "2023-04-09 12:41:30,593-rk0-train_contrast.py#284:iter = 0 of 11 completed\n",
      "2023-04-09 12:41:41,308-rk0-train_contrast.py#284:iter = 5 of 11 completed\n",
      "2023-04-09 12:41:50,458-rk0-train_contrast.py#284:iter = 10 of 11 completed\n",
      "2023-04-09 12:41:50,657-rk0-train_contrast.py#293:accuracy = 0.6935156614209951 mIoU = 0.5860314369826527\n",
      "2023-04-09 12:41:50,658-rk0-train_contrast.py#149:the best val result is: 0.6334671588565454\n",
      "2023-04-09 12:41:50,661-rk0-train_contrast.py#172:=========epoch[17]=========,Train\n",
      "2023-04-09 12:42:24,202-rk0-train_contrast.py#230:iter = 6350 of 37200 completed, LR = [0.008449694468649517, 0.08449694468649517, 0.08449694468649517] loss = 12.529373168945312\n",
      "2023-04-09 12:43:23,941-rk0-train_contrast.py#230:iter = 6400 of 37200 completed, LR = [0.008437368145060315, 0.08437368145060316, 0.08437368145060316] loss = 12.64947357425442\n",
      "2023-04-09 12:44:22,415-rk0-train_contrast.py#230:iter = 6450 of 37200 completed, LR = [0.008425039820281208, 0.08425039820281208, 0.08425039820281208] loss = 12.620483248252569\n",
      "2023-04-09 12:45:20,854-rk0-train_contrast.py#230:iter = 6500 of 37200 completed, LR = [0.00841270949073253, 0.0841270949073253, 0.0841270949073253] loss = 12.672199631814903\n",
      "2023-04-09 12:46:19,344-rk0-train_contrast.py#230:iter = 6550 of 37200 completed, LR = [0.008400377152822384, 0.08400377152822384, 0.08400377152822384] loss = 12.674714109445983\n",
      "2023-04-09 12:47:20,943-rk0-train_contrast.py#230:iter = 6600 of 37200 completed, LR = [0.008388042802946557, 0.08388042802946558, 0.08388042802946558] loss = 12.684038554718349\n",
      "2023-04-09 12:48:21,225-rk0-train_contrast.py#230:iter = 6650 of 37200 completed, LR = [0.008375706437488478, 0.08375706437488478, 0.08375706437488478] loss = 12.73417285895858\n",
      "2023-04-09 12:49:13,759-rk0-train_contrast.py#253:=========epoch[17]=========,Val\n",
      "2023-04-09 12:49:20,627-rk0-train_contrast.py#284:iter = 0 of 11 completed\n",
      "2023-04-09 12:49:31,322-rk0-train_contrast.py#284:iter = 5 of 11 completed\n",
      "2023-04-09 12:49:40,451-rk0-train_contrast.py#284:iter = 10 of 11 completed\n",
      "2023-04-09 12:49:40,696-rk0-train_contrast.py#293:accuracy = 0.7183949104719869 mIoU = 0.6223136321363265\n",
      "2023-04-09 12:49:40,697-rk0-train_contrast.py#149:the best val result is: 0.6334671588565454\n",
      "2023-04-09 12:49:40,699-rk0-train_contrast.py#172:=========epoch[18]=========,Train\n",
      "2023-04-09 12:49:48,420-rk0-train_contrast.py#230:iter = 6700 of 37200 completed, LR = [0.008363368052819132, 0.08363368052819131, 0.08363368052819131] loss = 11.750040435791016\n",
      "2023-04-09 12:50:46,794-rk0-train_contrast.py#230:iter = 6750 of 37200 completed, LR = [0.008351027645297023, 0.08351027645297023, 0.08351027645297023] loss = 12.753061363913796\n",
      "2023-04-09 12:51:45,274-rk0-train_contrast.py#230:iter = 6800 of 37200 completed, LR = [0.008338685211268085, 0.08338685211268085, 0.08338685211268085] loss = 12.709526089259557\n",
      "2023-04-09 12:52:43,454-rk0-train_contrast.py#230:iter = 6850 of 37200 completed, LR = [0.008326340747065642, 0.08326340747065641, 0.08326340747065641] loss = 12.659995663550593\n",
      "2023-04-09 12:53:41,777-rk0-train_contrast.py#230:iter = 6900 of 37200 completed, LR = [0.008313994249010317, 0.08313994249010319, 0.08313994249010319] loss = 12.689828835464105\n",
      "2023-04-09 12:54:40,032-rk0-train_contrast.py#230:iter = 6950 of 37200 completed, LR = [0.00830164571341, 0.0830164571341, 0.0830164571341] loss = 12.686561008528168\n",
      "2023-04-09 12:55:38,319-rk0-train_contrast.py#230:iter = 7000 of 37200 completed, LR = [0.008289295136559746, 0.08289295136559746, 0.08289295136559746] loss = 12.668180590770284\n",
      "2023-04-09 12:56:36,368-rk0-train_contrast.py#230:iter = 7050 of 37200 completed, LR = [0.00827694251474174, 0.08276942514741739, 0.08276942514741739] loss = 12.636608419284014\n",
      "2023-04-09 12:56:56,241-rk0-train_contrast.py#253:=========epoch[18]=========,Val\n",
      "2023-04-09 12:57:02,515-rk0-train_contrast.py#284:iter = 0 of 11 completed\n",
      "2023-04-09 12:57:13,196-rk0-train_contrast.py#284:iter = 5 of 11 completed\n",
      "2023-04-09 12:57:22,339-rk0-train_contrast.py#284:iter = 10 of 11 completed\n",
      "2023-04-09 12:57:22,569-rk0-train_contrast.py#293:accuracy = 0.7299954216018097 mIoU = 0.6261212897609146\n",
      "2023-04-09 12:57:22,570-rk0-train_contrast.py#149:the best val result is: 0.6334671588565454\n",
      "2023-04-09 12:57:22,572-rk0-train_contrast.py#172:=========epoch[19]=========,Train\n",
      "2023-04-09 12:58:02,650-rk0-train_contrast.py#230:iter = 7100 of 37200 completed, LR = [0.00826458784422521, 0.0826458784422521, 0.0826458784422521] loss = 12.34665737730084\n",
      "2023-04-09 12:59:00,912-rk0-train_contrast.py#230:iter = 7150 of 37200 completed, LR = [0.008252231121266378, 0.08252231121266378, 0.08252231121266378] loss = 12.568912850805075\n",
      "2023-04-09 12:59:58,975-rk0-train_contrast.py#230:iter = 7200 of 37200 completed, LR = [0.008239872342108372, 0.08239872342108373, 0.08239872342108373] loss = 12.568626984617763\n",
      "2023-04-09 13:00:57,055-rk0-train_contrast.py#230:iter = 7250 of 37200 completed, LR = [0.008227511502981183, 0.08227511502981183, 0.08227511502981183] loss = 12.529223645319703\n",
      "2023-04-09 13:01:55,137-rk0-train_contrast.py#230:iter = 7300 of 37200 completed, LR = [0.008215148600101568, 0.08215148600101568, 0.08215148600101568] loss = 12.515127001913832\n",
      "2023-04-09 13:02:53,379-rk0-train_contrast.py#230:iter = 7350 of 37200 completed, LR = [0.008202783629673013, 0.08202783629673015, 0.08202783629673015] loss = 12.487562014441608\n",
      "2023-04-09 13:03:51,510-rk0-train_contrast.py#230:iter = 7400 of 37200 completed, LR = [0.008190416587885638, 0.08190416587885639, 0.08190416587885639] loss = 12.520844047133988\n",
      "2023-04-09 13:04:36,942-rk0-train_contrast.py#253:=========epoch[19]=========,Val\n",
      "2023-04-09 13:04:42,671-rk0-train_contrast.py#284:iter = 0 of 11 completed\n",
      "2023-04-09 13:04:53,539-rk0-train_contrast.py#284:iter = 5 of 11 completed\n",
      "2023-04-09 13:05:02,742-rk0-train_contrast.py#284:iter = 10 of 11 completed\n",
      "2023-04-09 13:05:02,978-rk0-train_contrast.py#293:accuracy = 0.7545362654197963 mIoU = 0.6464043077971634\n",
      "2023-04-09 13:05:05,294-rk0-train_contrast.py#149:the best val result is: 0.6464043077971634\n",
      "2023-04-09 13:05:05,296-rk0-train_contrast.py#172:=========epoch[20]=========,Train\n",
      "2023-04-09 13:05:20,165-rk0-train_contrast.py#230:iter = 7450 of 37200 completed, LR = [0.008178047470916144, 0.08178047470916144, 0.08178047470916144] loss = 12.070305477489125\n",
      "2023-04-09 13:06:18,152-rk0-train_contrast.py#230:iter = 7500 of 37200 completed, LR = [0.008165676274927728, 0.0816567627492773, 0.0816567627492773] loss = 12.476716197904993\n"
     ]
    }
   ],
   "source": [
    "!now=$(date +\"%Y%m%d_%H%M%S\"); \\\n",
    "export CUDA_VISIBLE_DEVICES=1,2,3,9; \\\n",
    "python -m torch.distributed.launch --nproc_per_node=4 --master_port 2523 ../../train_contrast.py \\\n",
    "    --config=config.yaml \\\n",
    "    --batch_size 2 --batch_size_val 12 \\\n",
    "    --epochs 100 \\\n",
    "    --save_dir $now \\\n",
    "    2>&1 | tee log_$now.log"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
